---
title: "Statistisk inferens" 
bibliography: 
  referanser/03-ref.bib
editor_options: 
  chunk_output_type: console
---

## Introduksjon

Statistisk inferens er en type statistikk som omhandler metoder for å trekke konklusjoner om en populasjon basert på et utvalg. Målet er å generalisere funnene fra utvalget og bruke det til å si noe om hele populasjonen. En viktig del av statistisk inferens er å vurdere usikkerheten i estimatene, typisk ved hjelp av konfidensintervaller og p-verdier [@Cremers].

Effektstørrelser gir en kvantitativ vurdering av hvor betydelig en observert effekt er, og er ikke avhengig av utvalgsstørrelse. Dette er nyttig i forskning, da det hjelper med å forstå de praktiske betydningene av funnene man har gjort. Ved å kombinere statistisk inferens med effektstørrelser kan man bedre vurdere resultatene sine og sette det i en bred kontekst [@Cremers].

```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(ggtext)
library(gt)

set.seed(1)
population <- rnorm(1000000, mean = 1.5, sd = 3)

#lager to ulike utvalg der gruppe 1 er n=8 og gruppe 2 n=40
samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

samp2 <- data.frame(y = sample(population, 40, replace = FALSE))


m1 <- lm(y ~ 1, data = samp1)
m2 <- lm(y ~ 1, data = samp2)

sum1 <- summary(m1) 
sum2 <- summary(m2)
```


For å illustrer 

```{r, fig.width=6, fig.height=4}
#| echo: false
#| warning: false
#| message: false
#| label: fig-sample1
#| fig-cap: "Spredning i verdier for n = 8"


# plotter samp 1 og 2 for å illustrere den relative spredningen i utvalget
samp1 |> 
  ggplot(aes(y, 1)) + geom_point(size = 3, shape = 21, fill = "orange") +
  geom_vline(xintercept = coef(sum1)[1], color = "steelblue", linewidth = 1.5) +
  annotate("richtext", 
           x = coef(sum1)[1], 
           y = 0.99, 
           label = "estimate", 
           angle = -90) +
  coord_cartesian(y = c(0.98, 1.02)) +
  labs(subtitle = "Illustrasjon av spredning i verdier", 
       caption = "Utvalg 1 fra populasjonen (n = 8)",
       x = "", 
       y = "")
```


```{r, fig.width=6, fig.height=4}
#| echo: false
#| warning: false
#| message: false
#| label: fig-sample2
#| fig-cap: "Spredning i verdier for n = 40"


samp2 |> 
  ggplot(aes(y, 1)) + geom_point(size = 3, shape = 21, fill = "red") +
  geom_vline(xintercept = coef(sum2)[1], color = "steelblue", linewidth = 1.5) +
  scale_x_continuous(breaks = c(-2.5, 0, 2.5, 5, 7.5)) +
  annotate("richtext", 
           x = coef(sum2)[1], 
           y = 0.99, 
           label = "estimate", 
           angle = -90) +
  coord_cartesian(y = c(0.98, 1.02)) +
  labs(subtitle = "Illustrasjon av spredning i verdier",
       caption = "Utvalg 2 fra populasjonen (n = 40)", 
       x = "", 
       y = "")
```



## Forklaring av *T*-verdi, *P*-verdi, Standard Error (SE) og Estimat 

*T-verdien* er et mål som brukes i hypotesetesting for å vurdere om det er en signifikant forskjell mellom gjennomsnittet av et utvalg og et kjent eller hypotetisk populasjonsgjennomsnitt. *T*-verdiens størrelse er en indikasjon på hvor stor forskjell det er mellom utvalget og populasjonen. Jo større t-verdi, desto mer signifikant er forskjellen.

$t = \frac{(\overline{x}-\mu_{0})} {\frac{s} {\sqrt n}}$, der
$\overline{x}$ = gjennomsnittet av utvalget, $\mu_{0}$ = gjennomsnittet av populajsonen, s = standardavviket, n = størrelsen av utvalget

*P-verdien* sier noe om usikkerheten i trekningen av utvalget. Kanskje trakk man i sample 1 bare ekstreme verdier. Utvalget vil neppe bli en perfekt representasjon av populasjonen uansett hvordan man trekker ett utvalg. Dette er en usikkerhet man må ta høyde for i ulike studier og dette kan p-verdien hjelpe oss å si noe om. Om vi tar høyde for at nullhypotesten stemmer, hvor mange verdier kan vi forvente er mer ekstreme enn våre observasjoner. *p*-veriden måler altså observasjonene våre opp mot den spesifikke nullhypotesen. Lave *p*-verdier indikerer at det er lite sannsynlig at den observerte forskjellen skyldes tilfeldigheter, og en kan forkaste nullhypotesen. Motsatt indikerer høye *p*-verdier at den observerte forskjellen trolig skyldes tilfeldigheter og en har ikke godt nok grunnlag til å si at det er en forskjell mellom gruppene. 

*Standard error (SE)* er en måte å angi feilmarginen av et estimat eller måling. Sagt på en annen måte, beskriver SE variasjonen ved repeterte gjennomsnitt for et utvalg knyttet til en populasjon. Man benytter ofte sentralgrenseteoremet i denne sammenhengen, som sier at hvis man gjør en undersøkelse mange ganger, vil resulatene samle seg omkring den sanne verdien. Jo større utvalg, jo mindre feilmargin.
Manuelt kan man beregne SE ved å ta standardavviket og dele på
kvadratroten av antall observasjoner. Dette gir oss altså et svar på
hvor langt unna det sanne gjennomsnittet vi kan forvente å komme. I dette tilfellet ser en at SE for sample 1 er betydelig større enn i sample 2, nettopp pga et mindre utvalg i sample 1. En kan altså forvente å få verdier lenger unna den sanne gjennomsnittsverdien ved et mindre utvalg.

*Estmatet* er en verdi som blir kalkulert basert på et utvalg og blir brukt til å estimere noe om en populasjon. Det kan eksempelvis være et estimat på det sanne gjennomsnittet i en befolkning.  



## Hva bidrar til de ulike resulatene i de to studiene (m1 og m2)

Forskjellen mellom sample 1 og 2 er først og fremst antall som trekkes ut (utvalget). Med et større utvalg blir SE lavere, *t*-verdien høyere og *p*-verdien lavere, sammenlinket med et utvalg som er mindre. En får mindre variabilitet med større utvalg og større usikkerhet ved mindre utvalg. 



## Hvorfor benytter en begge "halene" i t-fordelingen (two-tailed test)

En two-tailed test tillater at man ser på mulighet for endring i begge
retninger, altså positiv og negativ retning. Når man undersøker ulike behandlinger, for eksempel for blodtrykk, vil man være interessert i å vurdere både positive og negative endringer mellom gruppene. En ser etter et avvik i begge retninger av fordelingen og ser om avviket er stort nok til å kunne forkaste nullhypotesen (ref. avsnitt om *t*-verdi over). Høye *t*-verdier referer ofte til lave *p*-verdier, som vil si at det er lite sannsynlig at den observerte forskjellen skyldes tilfeldigheter, gitt at nullhypotesen er sann. Ettersom en ser på forskjeller i begge retninger av fordelingen, må en doble *p*-verdien ved bruk av two-tailed test. 





```{r}
#| echo: false
#| warning: false
#| message: false


# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)
```

## Kalkuler standardavvik for estimat-variabelen og gjennomsnittet av se-variabelen for begge utvalgene.

Standard error: $SE = \frac{\sigma}{\sqrt n}$ , der $\sigma$ =
standardavviket for utvalget og n = antall i utvalget.

```{r}
#| echo: false
#| warning: false
#| message: false

sd_est_8 <- sd(results_8$estimate) 
mean_se_8 <- mean(results_8$se)

sd_est_40 <- sd(results_40$estimate)
mean_se_40 <- mean(results_40$se)

```

For utvalget med n=8 er standardavviket for snittet av utvalget
`r round(sd_est_8, digits = 3)` og gjennomsnittet av standardfeilen
`r round(mean_se_8, digits = 3)`. Altså tilnærmet likt. Det samme
gjelder for utvalget med n=40 (bare med mindre avvik) der
standardavviket for snittet av utvalget er
`r round(sd_est_40, digits = 3)` og gjennomsnittet av standardfeilen er
`r round(mean_se_40, digits = 3)`. Hvordan kan man definere
standardfeilen, sett i lys av disse variablene? På generell basis kan
man si at SE for et utvalg er et estimat på standardavviket til den
teoretiske fordelingen av gjennomsnitt. Observerer at når "n" (utvalget)
øker, vil standardfeilen synke (ref. formel for beregning av SE).

## Lag et histogram av *p*-verdiene for de to uvalgene. Hvordan kan histogrammene tolkes og hva forteller de om effekten av størrelsen av utvalget for statistisk styrke?

```{r}
#| echo: false
#| warning: false
#| message: false

library(ggtext)
library(dplyr)
library(gt)

# A two facets histogram can be created with ggplot2
results %>%
  ggplot(aes(pval)) + 
  geom_histogram(bins = 25, 
                 color = "black", 
                 fill = "orange") +
  facet_wrap(~ n) + 
  labs(x = "*p*-values", 
       y = "Number of simulations", 
       subtitle = "Fordelingen av *p*-verdier fra 1000 simuleringer", 
       caption = "Hver bar representerer antall simuleringer av en gitt *p*-verdi") +
  theme(axis.title.x = element_markdown()) +
theme(plot.subtitle = element_markdown()) +
  theme(plot.caption = element_markdown())


# Count the proportion of tests below a certain p-value for each 
results %>%
  filter(pval < 0.05) %>%
  group_by(n) %>%
  summarise(sig_results = n()/1000) |> 
  gt() |> 
  tab_caption("Summering av signifikante resultater") |> 
  cols_label(n = "Utvalgsstr.", 
             sig_results = "Signif. res. / 1000")
```

I histogrammet med n=8 kan er se stor variasjon innad i utvalgene. Ved
de 1000 simuleringene som er gjort er det sannsynlig at det har vært
stor spredning i de variablene som er trekt i samme utvalg (og motsatt).
Dermed vil disse enkelt-utvalgene gjøre utslag på *p*-verdien begge
veier. Ved å plotte det slik fremheves også tendensen til falsk-positive
simuleringer ved p = 0.05. En falsk positiv oppstår når en test
indikerer en signifikant effekt, slik at man forkaster nullhypotesten
(H~0~), men det egentlig ikke er en effekt der (H~0~ er sann).

## Antall observasjoner fra hvert utvalg som er under signifikansnivået på 0.05

```{r}
#| echo: false
#| warning: false
#| message: false

n_sig_8 <- results |> 
  filter(pval < 0.05) |> 
  filter(n != 40) |> 
  nrow()
n_sig_40 <- results |> 
  filter(pval < 0.05) |> 
  filter(n == 40) |> 
  nrow()

```

Setter signifikansnivå til p \< 0.05 Det er `r n_sig_40` tilfeller der p
\< 0.05 for utvalget med 40. Det er `r n_sig_8` tilfeller der p\< 0.05
for utvalget med 8.

## Estmerer effekten ved one-sample t-test

```{r}
#| echo: false
#| warning: false
#| message: false

# Using the pwr package
library(pwr)

pwr_8 <- pwr.t.test(n = 8, sig.level = 0.05, d = 1.5/3, type = "one.sample")
pwr_40 <- pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = "one.sample")

pwr_8
pwr_40
```

Effekt ved utavlget på 8 stk: `r round(pwr_8$power, digits = 3)`. Effekt
ved utvalget på 40 stk: `r round(pwr_40$power, digits = 3)`. En kan
forvente høyere effekt med et større utvalg. Dette observeres i vårt
tilfelle. Med høyere effekt, vil en også forvente å se større grad av
signifikans, altså en lavere *p*-verdi (som også er tilfellet i denne
simuleringen).

## Ved å benytte det nye datasettet: hvor mange tilfeller av "falsk positive"-tester vil vi komme over ved å repetere studien mange ganger?

```{r}
#| echo: false
#| warning: false
#| message: false

population <- rnorm(1000000, mean = 0, sd = 3)

# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
}

# Save the results in a combined data frame

results_null <- bind_rows(results_8, results_40)
```

```{r, fig.width=6, fig.height=4}
#| echo: false
#| warning: false
#| message: false

#lager histogram for koden over

ggplot(data = results_null, aes(pval)) +
  geom_histogram(binwidth = 0.05, 
                 color = "black", fill = "lightgreen",) +
facet_wrap(~ n) +
  labs(subtitle = "Fordelingen av *p*-verdier fra 1000 simuleringer", 
       caption = "Hver bar representerer antall simuleringer av en gitt *p*-verdi", 
       x = "*p*-verdier", 
       y = "Number of simulations") +
  theme(axis.title.x = element_markdown()) +
theme(plot.subtitle = element_markdown()) +
  theme(plot.caption = element_markdown())


```

```{r}
#| echo: false
#| warning: false
#| message: false

falsepos_8 <- results_null |> 
  filter(results_null$pval < 0.05, n == 8) |> 
  nrow()
  
falsepos_40 <- results_null |> 
  filter(results_null$pval < 0.05, n == 40) |> 
  nrow()

```

Ved å repetere studien 1000 ganger, vil vi komme over `r falsepos_8`
falsk-positive tester for utvalget med 8, og `r falsepos_40` for
utvalget med 40. Totalt antall falsk-positive tester blir
`r (falsepos_8 + falsepos_40)`.

